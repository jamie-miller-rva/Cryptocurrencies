{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Crypto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background:\n",
    "Accountability Accounting, a prominent investment bank, is interested in offering a new cryptocurrency investment portfolio for its customers. The company, however, is lost in the vast universe of cryptocurrencies. \n",
    "\n",
    "# Problem Statement:\n",
    "Identify what cryptocurrencies are on the trading market and how they could be grouped to create a classification system for this new investment.\n",
    "\n",
    "# Deliverables:\n",
    "* Deliverable 1: Preprocessing the Data for PCA\n",
    "* Deliverable 2: Reducing Data Dimensions Using PCA\n",
    "* Deliverable 3: Clustering Cryptocurrencies Using K-means\n",
    "* Deliverable 4: Visualizing Cryptocurrencies Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install plotly-express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hvplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jamie\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numpy\\__init__.py:143: UserWarning: mkl-service package failed to import, therefore Intel(R) MKL initialization ensuring its correct out-of-the box operation under condition when Gnu OpenMP had already been loaded by Python process is not assured. Please install mkl-service package, see http://github.com/IntelPython/mkl-service\n",
      "  from . import _distributor_init\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.7 from \"C:\\Users\\jamie\\anaconda3\\envs\\mlenv\\python.exe\"\n  * The NumPy version is: \"1.20.1\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed: The specified module could not be found.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numpy\\core\\multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[0;32m      8\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: The specified module could not be found.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5732eb3e877f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# import initial imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhvplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# from path import Path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\numpy\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \"\"\" % (sys.version_info[0], sys.version_info[1], sys.executable,\n\u001b[0;32m     47\u001b[0m         __version__, exc)\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.7 from \"C:\\Users\\jamie\\anaconda3\\envs\\mlenv\\python.exe\"\n  * The NumPy version is: \"1.20.1\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: DLL load failed: The specified module could not be found.\n"
     ]
    }
   ],
   "source": [
    "# import initial imports\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import hvplot.pandas\r\n",
    "# from path import Path\r\n",
    "import plotly.express as px\r\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.cluster import KMeans\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data for PCA (Deliverable 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for Data Preparation:\n",
    "* What knowledge do we hope to glean from running an unsupervised learning model on this dataset?\n",
    "* What data is available? What type? What is missing? What can be removed?\n",
    "* Is the data in a format that can be passed into an unsupervised learning model?\n",
    "* Can I quickly hand off this data for others to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the crypto_data.csv dataset.\n",
    "# data sorce: https://min-api.cryptocompare.com/data/all/coinlist\n",
    "file_path = \"./Resources/crypto_data.csv\"\n",
    "\n",
    "df_crypto = pd.read_csv(file_path)\n",
    "df_crypto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What knowledge do we hope to glean from running an unsupervised learning model on this dataset?\n",
    "\n",
    "Answer: Identify what cryptocurrencies are on the trading market and how they could be grouped to create a classification system for a new investment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What type of data is available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify missing values and dtypes using info() method\n",
    "df_crypto.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What data is missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find null values using isnull() method\n",
    "for column in df_crypto.columns:\n",
    "    print(f\"Column {column} has {df_crypto[column].isnull().sum()} null values\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the values counts for \"IsTrading\"\n",
    "df_crypto[\"IsTrading\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What data can be removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep all the crypto currencies that are being traded.\n",
    "Drop crypto currencies not trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all the cryptocurrencies that are being traded (\"True\").\n",
    "df_crypto_trading = df_crypto.loc[(df_crypto[\"IsTrading\"] == True)]\n",
    "df_crypto_trading[\"IsTrading\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crypto_trading.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the \"IsTrading\" column. \n",
    "new_df_crypto = df_crypto_trading.drop(['IsTrading'], axis=\"columns\")\n",
    "new_df_crypto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep all the cryptocurrencies that have a working algorithm.\n",
    "Drop those that don't have a working algorith (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view value_counts for Algorithm\n",
    "new_df_crypto[\"Algorithm\"].value_counts()\n",
    "\n",
    "# note: there are no null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows that have at least one null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_crypto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_crypto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values for \"ProofType\"\n",
    "new_df_crypto[\"ProofType\"].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values for \"TotalCoinsMined\"\n",
    "new_df_crypto[\"TotalCoinsMined\"].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for null values for \"TotalCoinSupply\"\n",
    "new_df_crypto[\"TotalCoinSupply\"].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep all the cryptocurrencies that are being mined\n",
    "drop those where TotalCoinsMined is less than or equal to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that have at least 1 null value.\n",
    "# this will be all rows where \"TotalCoinsMined\" is not a numeric values\n",
    "clean_df_crypto = new_df_crypto.dropna(how='any', axis='rows')\n",
    "clean_df_crypto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the rows that do not have coins being mined\n",
    "clean_df_crypto = clean_df_crypto[clean_df_crypto[\"TotalCoinsMined\"] > 0]\n",
    "clean_df_crypto.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recast \"TotalCoinsSupply\" as numeric\n",
    "# pandas.to_numeric(arg, errors='raise', downcast=None)\n",
    "supply_clean_df_crypto = clean_df_crypto.copy()\n",
    "supply_clean_df_crypto[\"TotalCoinSupply\"] = pd.to_numeric(supply_clean_df_crypto[\"TotalCoinSupply\"], errors='coerce')\n",
    "supply_clean_df_crypto.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new DataFrame that holds only the cryptocurrency names\n",
    "use the crypto_df DataFrame index as the index for this new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that holds only the cryptocurrencies names.\n",
    "df_crypto_names = supply_clean_df_crypto.copy()\n",
    "df_crypto_names = df_crypto_names[[\"CoinName\", \"Unnamed: 0\"]]\n",
    "\n",
    "# use the crypto_df DataFrame index as the index for this new DataFrame.\n",
    "df_crypto_names.set_index(\"Unnamed: 0\",drop=True, inplace=True)\n",
    "\n",
    "df_crypto_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the CoinName column from the crypto_df DataFrame \n",
    "since it's not going to be used on the clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crypto_df = supply_clean_df_crypto.copy()\n",
    "crypto_df.drop(columns=[\"CoinName\"], inplace=True)\n",
    "crypto_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index to \"Unnamed: 0\"\n",
    "crypto_df.set_index(\"Unnamed: 0\", drop=True, inplace=True)\n",
    "crypto_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The get_dummies() method \n",
    "to create variables for the text features, which are then stored in a new DataFrame, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_dummies() to create variables for text features.\n",
    "print(f\"crypto_df shape: {crypto_df.shape}\")\n",
    "\n",
    "X = crypto_df.copy()\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the string values into numerical ones using the get_dummies() method.\n",
    "X_encoded = pd.get_dummies(X, columns=[\"Algorithm\", \"ProofType\"])\n",
    "X_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the scale of column values using describe method\n",
    "X_encoded.describe()\n",
    "\n",
    "# note: when there are large differences in scale it will affect our machine learning model\n",
    "# the solution is to scale using StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize The features from the X DataFrame \n",
    "using the StandardScaler fit_transform() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data with StandardScaler().\n",
    "# create an instance of the StandardScaler method\n",
    "data_scaler = StandardScaler()\n",
    "\n",
    "# train and transform the data_scaler using the fit_transform() method\n",
    "X_scaled = data_scaler.fit_transform(X_encoded)\n",
    "X_scaled[: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confirm data processing is complete:\n",
    "* Null values are handled.\n",
    "* Only numerical data is used.\n",
    "* Values are scaled. In other words, data has been manipulated to ensure that the variance between the numbers won't skew results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing Data Dimensions Using PCA (Deliverable 2)\n",
    "PCA reduces the number of dimensions by transforming a large set of variables into a smaller one that contains most of the information in the original large set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to reduce dimension to three principal components.\n",
    "\n",
    "# initialize the PCA model\n",
    "pca = PCA(n_components= 3, random_state=5)\n",
    "\n",
    "# use X_scaled array and the pca model to reduce the components to 3\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Note: These new components are just the three main dimensions of variation \n",
    "# that contain most of the information in the original dataset.\n",
    "\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the principal components.\n",
    "# Transform PCA data into a DataFrame\n",
    "# use the index from X_encoded (Unnamed: 0)\n",
    "           \n",
    "pcs_df = pd.DataFrame(\n",
    "        data=X_pca,\n",
    "        columns= [\"PC 1\", \"PC 2\", \"PC 3\"],\n",
    "        index= X_encoded.index\n",
    ")\n",
    "\n",
    "pcs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the explained variance\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What this tells us is:\n",
    "* the first principal component contains 2.79% of the variance \n",
    "* the second contains 2.14% \n",
    "* the third contain 2.05%\n",
    "\n",
    "together the principal components contain only about 7% of the information (that is very low) but allows the ploting in 3D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Crytocurrencies Using K-Means (Deliverable 3)\n",
    "\n",
    "#### Finding the Best Value for `k` Using the Elbow Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an elbow curve to find the best value for K.\n",
    "\n",
    "# use the elbow in the curve with the generated principal components (pcs_df)\n",
    "# store values of K to plot in an empty list\n",
    "inertia = []\n",
    "k = list(range(1, 11)) # generates a list 1 to 10\n",
    "\n",
    "# iterate through K valeus and find inertia for the best K\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(pcs_df)\n",
    "    inertia.append(km.inertia_)\n",
    "    \n",
    "# create a dataframe (using a dict) to plot the elbow in the curve\n",
    "\n",
    "# create the dictionary\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "\n",
    "df_elbow_data = pd.DataFrame(elbow_data)\n",
    "df_elbow_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph the elbow data\n",
    "df_elbow_data.hvplot.line(x=\"k\", y=\"inertia\", xticks=k, title=\"Elbow Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the principal components data with the K-means algorithm with a K value of 4. \n",
    "\n",
    "Running K-Means with `k=4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model.\n",
    "model = KMeans(n_clusters= 4, random_state=0)\n",
    "\n",
    "# Fit the model with pcs_df\n",
    "model.fit(pcs_df)\n",
    "\n",
    "# Predict clusters\n",
    "predictions = model.predict(pcs_df)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new DataFrame named clustered_df \n",
    "by concatenating the crypto_df and pcs_df DataFrames on the same columns. The index should be the same as the crypto_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame (called clustered_df) using concat() method\n",
    "# that concats cryptocurrencies features (crypto_df and pcs_df)\n",
    "\n",
    "clustered_df = pd.concat([crypto_df, pcs_df], axis=1) # see defaults for concat\n",
    "clustered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakout the CoinNames from the dataframe and index using \"Unnamed: 0\"\n",
    "# Add a new column, \"CoinName\" to the clustered_df DataFrame that holds the names of the cryptocurrencies. \n",
    "# this requires df_crypto_names\n",
    "df_crypto_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add a new column, \"CoinName\" to the clustered_df DataFrame that holds the names of the cryptocurrencies. \n",
    "clustered_df[\"CoinName\"] = df_crypto_names[\"CoinName\"]\n",
    "\n",
    "#  Add a new column, \"Class\" to the clustered_df DataFrame that holds the predictions.\n",
    "# using the model.labels_ from the KMeans model fit with the pcs_df data\n",
    "clustered_df[\"Class\"] = model.labels_\n",
    "\n",
    "# Print the shape of the clustered_df\n",
    "print(clustered_df.shape)\n",
    "clustered_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Cryptocurrencies Results (Deliverable 4)\n",
    "\n",
    "#### Create a 3D scatter plot \n",
    "using the Plotly Express scatter_3d() function to plot the three clusters from the clustered_df DataFrame.\n",
    "https://plotly.com/python-api-reference/generated/plotly.express.scatter_3d.html#plotly-express-scatter-3d\n",
    "\n",
    "Add the CoinName and Algorithm columns to the hover_name and hover_data parameters, respectively, so each data point shows the CoinName and Algorithm on hover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.kaleido.scope.default_format = \"svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a 3D-Scatter with the PCA data and the clusters\n",
    "# plot the result in 3D\n",
    "fig = px.scatter_3d(\n",
    "    clustered_df,\n",
    "    x=\"PC 1\",\n",
    "    y=\"PC 2\",\n",
    "    z=\"PC 3\",\n",
    "    color=\"Class\",\n",
    "    symbol=\"Class\",\n",
    "    hover_name=\"CoinName\",\n",
    "    hover_data= [\"Algorithm\"],\n",
    "    width = 1000,\n",
    "    height = 750,\n",
    ")\n",
    "\n",
    "fig.update_layout(legend=dict(x=0,y=1))\n",
    "\n",
    "# save an image of the figure\n",
    "fig.write_image(\"./Images/fig1.svg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a table with tradable cryptocurrencies \n",
    "using the hvplot.table() function.\n",
    "https://hvplot.holoviz.org/reference/pandas/table.html#table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with tradable cryptocurrencies (by coin name).\n",
    "# example from docs df.hvplot.table(columns=['origin', 'name', 'yr'], sortable=True, selectable=True)\n",
    "# \n",
    "\n",
    "# to save plot\n",
    "plot = clustered_df[[\n",
    "    \"CoinName\",\n",
    "    \"Algorithm\",\n",
    "    \"ProofType\",\n",
    "    \"TotalCoinsMined\",\n",
    "    \"TotalCoinSupply\",\n",
    "    \"Class\"\n",
    "]].hvplot.table(sortable=True, selectable=True)\n",
    "\n",
    "hvplot.save(plot, './Images/Crypto_table.html')\n",
    "\n",
    "# to display in notebook\n",
    "clustered_df[[\n",
    "    \"CoinName\",\n",
    "    \"Algorithm\",\n",
    "    \"ProofType\",\n",
    "    \"TotalCoinsMined\",\n",
    "    \"TotalCoinSupply\",\n",
    "    \"Class\"\n",
    "]].hvplot.table(sortable=True, selectable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the total number of tradable cryptocurrencies in the clustered_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the total number of tradable cryptocurrencies (in data sorce: https://min-api.cryptocompare.com/data/all/coinlist)\n",
    "clustered_df.shape\n",
    "print(f\"There are {clustered_df.shape[0]} total tradable cryptocurrencies in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scale the TotalCoinSupply and TotalCoinsMined columns between the given range of zero and one.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data to create the scatter plot with tradable cryptocurrencies.\n",
    "# Use the MinMaxScaler().fit_transform method to scale the TotalCoinSupply and TotalCoinsMined columns between the given range of zero and one.\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# use fit_transform and identify X and y\n",
    "scatter_plot_data = scaler.fit_transform(\n",
    "    clustered_df[[\"TotalCoinSupply\", \"TotalCoinsMined\"]])\n",
    "                 \n",
    "scatter_plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new DataFrame using the clustered_df DataFrame index that contains the scaled data created above.\n",
    "\n",
    "#### Add the CoinName column from the clustered_df DataFrame to the new DataFrame.\n",
    "\n",
    "#### Add the Class column from the clustered_df DataFrame to the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame that has the scaled data with the clustered_df DataFrame index.\n",
    "df_for_plot = pd.DataFrame(\n",
    "    scatter_plot_data,\n",
    "    columns=[\"TotalCoinSupply\", \"TotalCoinsMined\"],\n",
    "    index=clustered_df.index    \n",
    ")\n",
    "\n",
    "df_for_plot\n",
    "\n",
    "# Add the \"CoinName\" column from the clustered_df DataFrame to the new DataFrame.\n",
    "df_for_plot[\"CoinName\"] = clustered_df[\"CoinName\"]\n",
    "\n",
    "# Add the \"Class\" column from the clustered_df DataFrame to the new DataFrame. \n",
    "df_for_plot[\"Class\"] = clustered_df[\"Class\"]\n",
    "\n",
    "df_for_plot.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an hvplot scatter plot \n",
    "with x=\"TotalCoinsMined\", y=\"TotalCoinSupply\", and by=\"Class\", and have it show the CoinName when you hover over the the data point.\n",
    "https://hvplot.holoviz.org/user_guide/Customization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a hvplot.scatter plot using x=\"TotalCoinsMined\" and y=\"TotalCoinSupply\".\n",
    "plot2 = df_for_plot.hvplot.scatter(\n",
    "    x=\"TotalCoinsMined\",\n",
    "    y=\"TotalCoinSupply\",\n",
    "    hover_cols=[\"Class\"],\n",
    "    by=\"Class\"\n",
    ")\n",
    "\n",
    "hvplot.save(plot2, './Images/Crypto_ScatterPlot.png')\n",
    "\n",
    "# to save in notebook\n",
    "# to display in notebook\n",
    "df_for_plot.hvplot.scatter(\n",
    "    x=\"TotalCoinsMined\",\n",
    "    y=\"TotalCoinSupply\",\n",
    "    hover_cols=[\"Class\"],\n",
    "    by=\"Class\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
